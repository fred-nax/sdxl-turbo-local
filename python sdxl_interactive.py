from diffusers import AutoPipelineForText2Image
import torch
import os
import time

# =========================
# CONFIG
# =========================
MODEL_NAME = "stabilityai/sdxl-turbo"   # Hugging Face model
OUT_DIR = "outputs"                     # output folder
IMG_WIDTH = 1024                         # largeur
IMG_HEIGHT = 1024                        # height
STEPS = 4                               # number of iterations (Fast Turbo with 4-6)
GUIDANCE = 2.0                          # guidance_scale (0 for Turbo
NUM_IMAGES = 1                          # number of images generated by prompt
# =========================

# V√©rifier si CUDA est dispo
if torch.cuda.is_available():
    device = "cuda"
    gpu_name = torch.cuda.get_device_name(0)
    print(f"GPU usage: {gpu_name}")
else:
    device = "cpu"
    print("‚ö†Ô∏è No GPU detected, generating with CPU (slow)")

# Charger le pipeline
print("üîÑ Chargement du mod√®le...")
pipe = AutoPipelineForText2Image.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
    variant="fp16" if device == "cuda" else None
).to(device)

# Cr√©er dossier output
os.makedirs(OUT_DIR, exist_ok=True)

print("SDXL-Turbo ready! Press 'exit' to quit.\n")

while True:
    prompt = input("Enter your prompt (or 'exit' to quit) : ").strip()
    if prompt.lower() == "exit":
        print("Bye !")
        break
    if not prompt:
        continue

    print(f"Generating {NUM_IMAGES} images for: {prompt}")
    start_time = time.time()

    for i in range(NUM_IMAGES):
        image = pipe(
            prompt,
            num_inference_steps=STEPS,
            guidance_scale=GUIDANCE,
            width=IMG_WIDTH,
            height=IMG_HEIGHT
        ).images[0]

        filename = f"{OUT_DIR}/{int(time.time())}_{i}.png"
        image.save(filename)
        print(f"   Saved Image: {filename}")

    elapsed = time.time() - start_time
    print(f"Total time : {elapsed:.2f} secondes ({elapsed/NUM_IMAGES:.2f} s/img)\n")
